{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTree():\n",
    "    '''\n",
    "    Train Data:\n",
    "    X in shape (m, n)\n",
    "    m = num_samples, n = num_features,\n",
    "    Only one_hot values, no multiclass or regression\n",
    "    Features Must Not be single valued: e.g \n",
    "    >>> X = np.array([[0],[0],[0],[0],[0],[0],[0]])\n",
    "    >>> y = np.array([ 0 , 1 , 0 , 0 , 1 , 1 , 0 ])\n",
    "    '''\n",
    "    class Node():\n",
    "\n",
    "        def __init__(self, depth=0, parent=None):\n",
    "            self.depth = depth\n",
    "            self.parent = parent\n",
    "            self.h = 1\n",
    "\n",
    "    class Decisive(Node):\n",
    "\n",
    "        def __init__(self, feature, depth=0, parent=None):\n",
    "            self.feature = feature\n",
    "            self.children = {}\n",
    "            self.received_features = None\n",
    "            super().__init__(depth=depth, parent=parent)\n",
    "            \n",
    "\n",
    "\n",
    "    class Root(Decisive):\n",
    "        \n",
    "        def __init__(self,feature):\n",
    "            super().__init__(feature=feature, )\n",
    "\n",
    "    class Decision(Decisive):\n",
    "        \n",
    "        def __init__(self, feature, parent, depth=0, ):\n",
    "            super().__init__(feature=feature, depth=depth,  parent=parent)\n",
    "\n",
    "    class Leaf(Node):\n",
    "        \n",
    "        def __init__(self, parent, confidence=1, depth=1,output=1):\n",
    "            self.confidence = confidence\n",
    "            self.output = output\n",
    "            super().__init__(depth=depth, parent=parent)\n",
    "            \n",
    "\n",
    "    def __init__(self, threshold=1, depth=3):\n",
    "        self.threshold = np.clip(threshold, 0, 1)\n",
    "        self.max_depth=np.maximum(1,depth)\n",
    "        self.root  = None\n",
    "       \n",
    "\n",
    "\n",
    "    def H(self, x) -> int:\n",
    "        if x == 0 or x ==1:\n",
    "            return 0\n",
    "        return -x*np.log2(x) - (1-x) * np.log2(1-x)\n",
    "    \n",
    "    def split(self, X, feature):\n",
    "        '''\n",
    "        Returns\n",
    "        ======================\n",
    "        feature=True, feature=False\n",
    "        '''\n",
    "        return X[X[:,feature]==1], X[X[:,feature]==0]\n",
    "        \n",
    "    def information_gain(self, X, y, feature):\n",
    "        '''\n",
    "        Return \n",
    "        =================\n",
    "        Information gain, whether to flip positive and negative\n",
    "        '''\n",
    "        if y.size == 0:\n",
    "            raise KeyError('Y got size of zero')\n",
    "        if y.mean() == 0 or y.mean() == 1:\n",
    "            raise ValueError('Completely Pure Node recieved')\n",
    "        X = np.concatenate([X,y.reshape(-1,1)], axis=-1)\n",
    "\n",
    "        tot = X.shape[0]\n",
    "        \n",
    "        positive, negative = self.split(X,feature)\n",
    "        \n",
    "        if positive.size == 0 or negative.size== 0:\n",
    "            return 0\n",
    "\n",
    "        w1, w0 = positive.shape[0]/tot ,negative.shape[0]/tot\n",
    "        \n",
    "        p1, p0 =  (positive[:,-1]).mean(), (negative[:,-1]).mean()\n",
    "\n",
    "        return self.H(np.mean(y)) - (w1 * self.H(p1) + w0 * self.H(p0))\n",
    "\n",
    "    def get_best(self, X :np.ndarray,y :np.ndarray) -> int:\n",
    "        '''\n",
    "        Get the best feature to split on\n",
    "        \n",
    "        Returns :\n",
    "        _________________________________\n",
    "        \n",
    "        best_feature_column\n",
    "        '''\n",
    "        best = 0\n",
    "        max = 0\n",
    "        for i in range(X.shape[-1]):\n",
    "            x= self.information_gain(X,y,i)\n",
    "            if best < x:\n",
    "                best = x\n",
    "                max = i\n",
    "        return max\n",
    "\n",
    "\n",
    "    def train(self, X, y, node : Decisive= None, verbose=False):\n",
    "        \n",
    "        end = False\n",
    "        # print('Current data\\n', X, '\\n', y)\n",
    "        removes = []\n",
    "        for f in range(X.shape[-1]):\n",
    "            if X[:,f].mean()==0 or X[:,f].mean()==1:\n",
    "                removes.append(f)\n",
    "        if len(removes):\n",
    "            X=np.delete(X, removes, axis=-1)\n",
    "            node.received_features = np.delete(node.received_features, removes, axis=0)\n",
    "\n",
    "            # print('-----------------------------------')\n",
    "            # print('Current data\\n', X, '\\n', y)\n",
    "        if node is not None:\n",
    "            prob = y.mean()\n",
    "            p = np.maximum(prob, 1-prob)\n",
    "            if verbose:\n",
    "                print('Confidence', f'{p:4f}', 'Num Samples at Node :' , len(y))\n",
    "            node.h = self.H(p)\n",
    "            if p >= self.threshold:\n",
    "                end = True\n",
    "                if verbose:\n",
    "                    print('Threshold Met ')\n",
    "            elif X.size == 0:\n",
    "                end=True\n",
    "                if verbose:\n",
    "                    print('End of Features')\n",
    "            elif node.depth == self.max_depth:\n",
    "                end=True\n",
    "                if verbose:\n",
    "                    print('Maximum Depth Reached')\n",
    "            if end:\n",
    "                node : self.Leaf = self.Leaf(parent=node.parent, confidence=p, depth=node.depth)\n",
    "                node.output = int(prob>=0.5)\n",
    "                node.h = self.H(p)\n",
    "                return node\n",
    "            if verbose:\n",
    "                print('Threshold Not met ')\n",
    "\n",
    "        if node is None:\n",
    "            if verbose:\n",
    "                print('Initializing Root')\n",
    "            node = self.Root(feature=None)\n",
    "            self.root =  node\n",
    "            node.h = self.H(y.mean())\n",
    "            node.received_features = np.arange(X.shape[-1]) \n",
    "        \n",
    "        if verbose:\n",
    "            print('Getting Best feature')\n",
    "        best_feature = self.get_best(X, y)\n",
    "        node.feature = node.received_features[best_feature]\n",
    "        if verbose:\n",
    "            print('Retrieved best feature : ',node.feature)\n",
    "\n",
    "        p,n = self.split(X = np.concatenate([X,y.reshape(-1,1)], axis=-1), feature=best_feature)\n",
    "        positive,  pos_y, negative, neg_y = p[:,:-1], p[:,-1], n[:,:-1], n[:,-1]\n",
    "        # print('Positive split : \\n', positive,'\\n', pos_y)\n",
    "        # print('Negative split : \\n', negative,'\\n', neg_y)\n",
    "   \n",
    "        for i, (X,y) in enumerate(([negative, neg_y], [positive, pos_y])):\n",
    "            if verbose:\n",
    "                print(f'Setting Child {i} of Depth' ,node.depth+1)\n",
    "            n = self.Decisive(feature=None,depth=node.depth+1, parent=node)\n",
    "            n.received_features = np.delete(node.received_features, best_feature, axis=-1)\n",
    "            node.children[i] = self.train(X=np.delete(X, best_feature, axis=-1), y=y,node=n, verbose=verbose)\n",
    "        return node\n",
    "    \n",
    "    def pretty_print(self, node=None):\n",
    "\n",
    "        if self.root is None:\n",
    "            raise LookupError('Unntrained Decision Tree')\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        print('='+'======'*node.depth+'>', 'Depth :', node.depth,'    |||     Entropy : ', f'{node.h:2f}',  end='')\n",
    "        if type(node) == self.Leaf:\n",
    "            print('   |||    Confidence', f'{node.confidence:2f}', '   |||    Output', node.output)\n",
    "            return\n",
    "        else:\n",
    "            print('   |||    Feature', node.feature, '|||   Num Features: ', len(node.received_features))\n",
    "        for child in node.children.values():\n",
    "            self.pretty_print(child)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Must receive shape (m,n)\n",
    "        m = num_fsamples - (1>=)\n",
    "        n = num_features - (train_data_shape)\n",
    "        '''\n",
    "        preds = []\n",
    "        for sample in X:\n",
    "            node : self.Decisive = self.root\n",
    "            while type(node)!=self.Leaf:\n",
    "\n",
    "                node = node.children[sample[node.feature]]\n",
    "            preds.append(node.output)\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def evaluate(self, X, y ):\n",
    "        preds = self.predict(X)\n",
    "        return (y==preds).mean()\n",
    "       \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [0, 1, 0, 1, 1],\n",
       "        [1, 1, 1, 0, 1],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 0, 1, 1, 1]]),\n",
       " array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.random.randint(size =(10,3), low=0, high=2)\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])\n",
    "features = np.array([\n",
    "    [0,0,0,0,0,0,1,1,1,1],\n",
    "    [0,0,0,0,0,1,1,1,1,0],\n",
    "    [0,0,0,0,0,0,1,1,1,1],\n",
    "    [0,1,0,0,1,1,0,1,1,1],\n",
    "    [1,1,0,0,1,1,1,0,1,1]]).T\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Depth : 0     |||     Entropy :  1.0   |||    Feature 0 |||   Num Features:  5\n",
      "=======> Depth : 1     |||     Entropy :  0.6500224216483541   |||    Feature 1 |||   Num Features:  3\n",
      "=============> Depth : 2     |||     Entropy :  0   |||    Confidence 1.0    |||    Output 1\n",
      "=============> Depth : 2     |||     Entropy :  0   |||    Confidence 1.0    |||    Output 0\n",
      "=======> Depth : 1     |||     Entropy :  0   |||    Confidence 1.0    |||    Output 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1 = BinaryTree()\n",
    "tree1.train(X=features, y=labels)\n",
    "tree1.pretty_print()\n",
    "tree1.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Root\n",
      "Getting Best feature\n",
      "Retrieved best feature :  3\n",
      "Setting Child 0 of Depth 1\n",
      "Confidence 0.652174 Num Samples at Node : 23\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  5\n",
      "Setting Child 0 of Depth 2\n",
      "Confidence 0.875000 Num Samples at Node : 8\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  9\n",
      "Setting Child 0 of Depth 3\n",
      "Confidence 1.000000 Num Samples at Node : 5\n",
      "Threshold Met \n",
      "Setting Child 1 of Depth 3\n",
      "Confidence 0.666667 Num Samples at Node : 3\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  1\n",
      "Setting Child 0 of Depth 4\n",
      "Confidence 1.000000 Num Samples at Node : 1\n",
      "Threshold Met \n",
      "Setting Child 1 of Depth 4\n",
      "Confidence 1.000000 Num Samples at Node : 2\n",
      "Threshold Met \n",
      "Setting Child 1 of Depth 2\n",
      "Confidence 0.533333 Num Samples at Node : 15\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  6\n",
      "Setting Child 0 of Depth 3\n",
      "Confidence 0.600000 Num Samples at Node : 10\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  4\n",
      "Setting Child 0 of Depth 4\n",
      "Confidence 1.000000 Num Samples at Node : 3\n",
      "Threshold Met \n",
      "Setting Child 1 of Depth 4\n",
      "Confidence 0.571429 Num Samples at Node : 7\n",
      "Maximum Depth Reached\n",
      "Setting Child 1 of Depth 3\n",
      "Confidence 0.800000 Num Samples at Node : 5\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  0\n",
      "Setting Child 0 of Depth 4\n",
      "Confidence 1.000000 Num Samples at Node : 4\n",
      "Threshold Met \n",
      "Setting Child 1 of Depth 4\n",
      "Confidence 1.000000 Num Samples at Node : 1\n",
      "Threshold Met \n",
      "Setting Child 1 of Depth 1\n",
      "Confidence 0.555556 Num Samples at Node : 27\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  5\n",
      "Setting Child 0 of Depth 2\n",
      "Confidence 0.733333 Num Samples at Node : 15\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  4\n",
      "Setting Child 0 of Depth 3\n",
      "Confidence 1.000000 Num Samples at Node : 7\n",
      "Threshold Met \n",
      "Setting Child 1 of Depth 3\n",
      "Confidence 0.500000 Num Samples at Node : 8\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  0\n",
      "Setting Child 0 of Depth 4\n",
      "Confidence 1.000000 Num Samples at Node : 2\n",
      "Threshold Met \n",
      "Setting Child 1 of Depth 4\n",
      "Confidence 0.666667 Num Samples at Node : 6\n",
      "Maximum Depth Reached\n",
      "Setting Child 1 of Depth 2\n",
      "Confidence 0.666667 Num Samples at Node : 12\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  9\n",
      "Setting Child 0 of Depth 3\n",
      "Confidence 0.666667 Num Samples at Node : 6\n",
      "Threshold Not met \n",
      "Getting Best feature\n",
      "Retrieved best feature :  1\n",
      "Setting Child 0 of Depth 4\n",
      "Confidence 0.666667 Num Samples at Node : 3\n",
      "Maximum Depth Reached\n",
      "Setting Child 1 of Depth 4\n",
      "Confidence 1.000000 Num Samples at Node : 3\n",
      "Threshold Met \n",
      "Setting Child 1 of Depth 3\n",
      "Confidence 1.000000 Num Samples at Node : 6\n",
      "Threshold Met \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([1,1,1,1,1,0,0,0,1,0,0,1,1,0,1,0,1])\n",
    "features = np.array([\n",
    "    [0,0,1,0,0,0,1,1,0,1,1,0,1,0,0,1,1],\n",
    "    [0,1,0,0,0,1,1,0,1,0,1,0,1,0,1,1,1],\n",
    "    [1,0,1,1,0,0,1,1,1,1,1,0,0,0,0,1,0],\n",
    "    [0,1,0,0,1,1,0,1,1,1,1,0,1,0,1,1,1],\n",
    "    [1,1,0,0,1,1,1,0,1,1,1,0,1,0,1,0,1]]).T\n",
    "samples = 50\n",
    "features = 10\n",
    "labels = np.random.randint(size=(samples,), low=0, high=2)\n",
    "features = np.random.randint(size=(samples,features), low=0, high=2)\n",
    "tree1 = BinaryTree(threshold=1,depth=4)\n",
    "tree1.train(X=features, y=labels, verbose=True)\n",
    "tree1.evaluate(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Depth : 0     |||     Entropy :  0.998846   |||    Feature 4 |||   Num Features:  5\n",
      "=======> Depth : 1     |||     Entropy :  0.950956   |||    Feature 2 |||   Num Features:  4\n",
      "=============> Depth : 2     |||     Entropy :  0.970951   |||    Feature 0 |||   Num Features:  3\n",
      "===================> Depth : 3     |||     Entropy :  0.985228   |||    Feature 3 |||   Num Features:  2\n",
      "=========================> Depth : 4     |||     Entropy :  1.000000   |||    Feature 1 |||   Num Features:  1\n",
      "===============================> Depth : 5     |||     Entropy :  1.000000   |||    Confidence 0.500000    |||    Output 1\n",
      "===============================> Depth : 5     |||     Entropy :  1.000000   |||    Confidence 0.500000    |||    Output 1\n",
      "=========================> Depth : 4     |||     Entropy :  0.918296   |||    Confidence 0.666667    |||    Output 0\n",
      "===================> Depth : 3     |||     Entropy :  0.811278   |||    Feature 1 |||   Num Features:  2\n",
      "=========================> Depth : 4     |||     Entropy :  0.000000   |||    Confidence 1.000000    |||    Output 1\n",
      "=========================> Depth : 4     |||     Entropy :  0.918296   |||    Confidence 0.666667    |||    Output 1\n",
      "=============> Depth : 2     |||     Entropy :  0.413817   |||    Feature 0 |||   Num Features:  3\n",
      "===================> Depth : 3     |||     Entropy :  0.650022   |||    Feature 1 |||   Num Features:  2\n",
      "=========================> Depth : 4     |||     Entropy :  0.811278   |||    Feature 3 |||   Num Features:  1\n",
      "===============================> Depth : 5     |||     Entropy :  0.000000   |||    Confidence 1.000000    |||    Output 0\n",
      "===============================> Depth : 5     |||     Entropy :  1.000000   |||    Confidence 0.500000    |||    Output 1\n",
      "=========================> Depth : 4     |||     Entropy :  0.000000   |||    Confidence 1.000000    |||    Output 0\n",
      "===================> Depth : 3     |||     Entropy :  0.000000   |||    Confidence 1.000000    |||    Output 0\n",
      "=======> Depth : 1     |||     Entropy :  0.965636   |||    Feature 0 |||   Num Features:  4\n",
      "=============> Depth : 2     |||     Entropy :  0.985228   |||    Feature 1 |||   Num Features:  3\n",
      "===================> Depth : 3     |||     Entropy :  0.000000   |||    Confidence 1.000000    |||    Output 0\n",
      "===================> Depth : 3     |||     Entropy :  0.970951   |||    Feature 2 |||   Num Features:  2\n",
      "=========================> Depth : 4     |||     Entropy :  1.000000   |||    Confidence 0.500000    |||    Output 1\n",
      "=========================> Depth : 4     |||     Entropy :  0.918296   |||    Feature 3 |||   Num Features:  1\n",
      "===============================> Depth : 5     |||     Entropy :  1.000000   |||    Confidence 0.500000    |||    Output 1\n",
      "===============================> Depth : 5     |||     Entropy :  0.000000   |||    Confidence 1.000000    |||    Output 1\n",
      "=============> Depth : 2     |||     Entropy :  0.896038   |||    Feature 3 |||   Num Features:  3\n",
      "===================> Depth : 3     |||     Entropy :  0.764205   |||    Feature 1 |||   Num Features:  2\n",
      "=========================> Depth : 4     |||     Entropy :  0.811278   |||    Feature 2 |||   Num Features:  1\n",
      "===============================> Depth : 5     |||     Entropy :  1.000000   |||    Confidence 0.500000    |||    Output 1\n",
      "===============================> Depth : 5     |||     Entropy :  0.000000   |||    Confidence 1.000000    |||    Output 1\n",
      "=========================> Depth : 4     |||     Entropy :  0.721928   |||    Feature 2 |||   Num Features:  1\n",
      "===============================> Depth : 5     |||     Entropy :  0.000000   |||    Confidence 1.000000    |||    Output 1\n",
      "===============================> Depth : 5     |||     Entropy :  0.918296   |||    Confidence 0.666667    |||    Output 1\n",
      "===================> Depth : 3     |||     Entropy :  0.985228   |||    Feature 1 |||   Num Features:  2\n",
      "=========================> Depth : 4     |||     Entropy :  0.000000   |||    Confidence 1.000000    |||    Output 1\n",
      "=========================> Depth : 4     |||     Entropy :  1.000000   |||    Feature 2 |||   Num Features:  1\n",
      "===============================> Depth : 5     |||     Entropy :  1.000000   |||    Confidence 0.500000    |||    Output 1\n",
      "===============================> Depth : 5     |||     Entropy :  1.000000   |||    Confidence 0.500000    |||    Output 1\n"
     ]
    }
   ],
   "source": [
    "tree1.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1.evaluate(features, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
